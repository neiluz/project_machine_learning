{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightgray; color:black; padding:10px; border-radius:5px;\">\n",
    "  <h1>Sprint 4</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 4.1: Extracci칩n de datos via APY y Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 游꿢 **Objetivo:**\n",
    "Extraer datos de una **API** y realizar **Web Scraping** utilizando **Python**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Ejercicio N췈 1. Consumir una API** : Selecciona una API p칰blica y extrae datos utilizando Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Recomendaci칩n Personalizada de Espacios de Trabajo Remoto en Barcelona Basada en Productividad y Condiciones Clim치ticas\"**\n",
    "\n",
    "**Objetivo**\n",
    "El objetivo de esta primera fase es crear un dataset estructurado que combine informaci칩n sobre los espacios de trabajo remoto disponibles en Barcelona y las condiciones clim치ticas actuales. A trav칠s de llamadas a las APIs p칰blicas de Foursquare y OpenWeather, se recopilar치n datos sobre cafeter칤as, coworkings y bibliotecas, junto con informaci칩n clim치tica en tiempo real (temperatura, humedad, viento, etc.). Este dataset servir치 como base para futuras recomendaciones personalizadas que optimicen la productividad de los usuarios en funci칩n de sus preferencias y el clima.\n",
    "\n",
    "**Justificaci칩n**\n",
    "Con el auge del trabajo remoto, cada vez m치s personas buscan espacios fuera de casa que les proporcionen el ambiente adecuado para ser productivos. Sin embargo, factores como el clima y el tipo de lugar pueden influir considerablemente en la experiencia de trabajo. Por ejemplo, un d칤a soleado puede hacer que los usuarios prefieran trabajar en una terraza, mientras que en d칤as lluviosos opten por espacios cerrados y tranquilos.\n",
    "\n",
    "Este proyecto, centrado en Barcelona, busca aprovechar las condiciones clim치ticas actuales para recomendar los mejores lugares para trabajar de manera remota. La creaci칩n de un dataset a partir de las APIs de Foursquare y OpenWeather es esencial para recopilar informaci칩n relevante que pueda luego alimentar un sistema de recomendaci칩n inteligente, mejorando la experiencia del trabajador remoto al ofrecerle sugerencias personalizadas seg칰n el clima y sus preferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias a utilizar\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las variables desde el archivo .env\n",
    "load_dotenv(dotenv_path='/home/ngonzalez/mi_pagina_personal/.env')\n",
    "\n",
    "# Acceder a las claves desde el entorno\n",
    "foursquare_api_key = os.getenv('FOURSQUARE_API_KEY')\n",
    "openweather_api_key = os.getenv('OPENWEATHER_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autenticaci칩n exitosa. Conexi칩n establecida.\n",
      "{'results': [{'fsq_id': '4af1b973f964a52083e221e3', 'categories': [{'id': 12082, 'name': 'Organization', 'short_name': 'Organization', 'plural_name': 'Organizations', 'icon': {'prefix': 'https://ss3.4sqi.net/img/categories_v2/building/default_', 'suffix': '.png'}}], 'chains': [], 'closed_bucket': 'VeryLikelyOpen', 'distance': 318, 'geocodes': {'drop_off': {'latitude': 41.387331, 'longitude': 2.175087}, 'main': {'latitude': 41.38759, 'longitude': 2.175354}, 'roof': {'latitude': 41.387574, 'longitude': 2.17532}}, 'link': '/v3/places/4af1b973f964a52083e221e3', 'location': {'address': 'Calle Palau de la M칰sica 4-6', 'admin_region': 'Catalu침a', 'country': 'ES', 'cross_street': 'Sant Pere m칠s Alt', 'formatted_address': 'Calle Palau de la M칰sica 4-6 (Sant Pere m칠s Alt), 08003 Barcelona Catalunya', 'locality': 'Barcelona', 'postcode': '08003', 'region': 'Catalunya'}, 'name': 'Palau de la M칰sica Catalana', 'related_places': {'children': [{'fsq_id': '51c2e6a1498e07baf2ce2a33', 'categories': [{'id': 13034, 'name': 'Caf칠', 'short_name': 'Caf칠', 'plural_name': 'Caf칠s', 'icon': {'prefix': 'https://ss3.4sqi.net/img/categories_v2/food/cafe_', 'suffix': '.png'}}], 'name': 'Caf칟 Palau'}]}, 'timezone': 'Europe/Madrid'}], 'context': {'geo_bounds': {'circle': {'center': {'latitude': 41.3851, 'longitude': 2.1734}, 'radius': 22000}}}}\n"
     ]
    }
   ],
   "source": [
    "#Test API foursquare\n",
    "url = \"https://api.foursquare.com/v3/places/search?ll=41.3851,2.1734&limit=1\"\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Authorization\": f\"{foursquare_api_key}\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Autenticaci칩n exitosa. Conexi칩n establecida.\")\n",
    "    data = response.json()\n",
    "    print(data)\n",
    "else:\n",
    "    print(f\"Error en la solicitud: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autenticaci칩n exitosa. Conexi칩n establecida.\n",
      "{'coord': {'lon': 2.1692, 'lat': 41.387}, 'weather': [{'id': 801, 'main': 'Clouds', 'description': 'few clouds', 'icon': '02d'}], 'base': 'stations', 'main': {'temp': 23.23, 'feels_like': 22.99, 'temp_min': 21.83, 'temp_max': 24.7, 'pressure': 1023, 'humidity': 53, 'sea_level': 1023, 'grnd_level': 1017}, 'visibility': 10000, 'wind': {'speed': 2.06, 'deg': 120}, 'clouds': {'all': 20}, 'dt': 1729423242, 'sys': {'type': 2, 'id': 2003688, 'country': 'ES', 'sunrise': 1729404534, 'sunset': 1729443774}, 'timezone': 7200, 'id': 6544106, 'name': 'Ciutat Vella', 'cod': 200}\n"
     ]
    }
   ],
   "source": [
    "# TEST Api open weather - Coordenadas de Barcelona\n",
    "latitud = 41.3851\n",
    "longitud = 2.1734\n",
    "\n",
    "# URL de la API de OpenWeather con tu clave API\n",
    "openweather_api_key = openweather_api_key\n",
    "url = f\"http://api.openweathermap.org/data/2.5/weather?lat={latitud}&lon={longitud}&appid={openweather_api_key}&units=metric\"\n",
    "\n",
    "# Hacer la solicitud a OpenWeather\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Autenticaci칩n exitosa. Conexi칩n establecida.\")\n",
    "    data = response.json()\n",
    "    print(data)\n",
    "else:\n",
    "    print(f\"Error en la solicitud: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Extracci칩n de datos en Foursquare API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci칩n para buscar lugares en Foursquare usando query y categor칤as\n",
    "def buscar_lugares_por_query(api_key, coords, query, categorias, limite=50, total_resultados=200):\n",
    "    \"\"\"\n",
    "    Funci칩n para buscar lugares en Foursquare usando query y categor칤as, con paginaci칩n para obtener m치s resultados.\n",
    "    \n",
    "    Par치metros:\n",
    "    api_key (str): Clave API de Foursquare.\n",
    "    coords (str): Coordenadas de la ciudad en formato \"latitud,longitud\".\n",
    "    query (str): Palabra clave para buscar (e.g., 'wifi', 'terraza').\n",
    "    categorias (str): Categor칤as de los lugares a buscar, separadas por comas.\n",
    "    limite (int): N칰mero m치ximo de lugares a devolver por solicitud (m치ximo permitido por Foursquare es 50).\n",
    "    total_resultados (int): N칰mero total de resultados que quieres obtener.\n",
    "    \n",
    "    Retorna:\n",
    "    DataFrame con los lugares encontrados (nombre, direcci칩n, categor칤a, coordenadas) y la query como tag.\n",
    "    \"\"\"\n",
    "    places = []\n",
    "    offset = 0  # Inicia en 0 para paginaci칩n\n",
    "    while len(places) < total_resultados:\n",
    "        # URL de la Foursquare API con paginaci칩n y query\n",
    "        url = f\"https://api.foursquare.com/v3/places/search?ll={coords}&query={query}&categories={categorias}&limit={limite}&offset={offset}\"\n",
    "        \n",
    "        headers = {\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Authorization\": f\"{api_key}\"\n",
    "        }\n",
    "        \n",
    "        # Realizar la solicitud a la API\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            for place in data['results']:\n",
    "                categorias_lugar = [cat['name'] for cat in place['categories']]\n",
    "                place_info = {\n",
    "                    'nombre': place['name'],\n",
    "                    'direccion': place['location']['formatted_address'],\n",
    "                    'categorias': categorias_lugar,\n",
    "                    'coordenadas': f\"{place['geocodes']['main']['latitude']},{place['geocodes']['main']['longitude']}\",\n",
    "                    'tag': query  # Agregar la query como un tag\n",
    "                }\n",
    "                places.append(place_info)\n",
    "            \n",
    "            # Aumentar el offset para la siguiente p치gina de resultados\n",
    "            offset += limite\n",
    "            \n",
    "            # Agregar un retraso entre las solicitudes para evitar superar el l칤mite de la API\n",
    "            time.sleep(1)  # Puedes ajustar este valor seg칰n sea necesario\n",
    "        \n",
    "        else:\n",
    "            print(f\"Error en la solicitud: {response.status_code}\")\n",
    "            break\n",
    "    \n",
    "    # Convertir a DataFrame\n",
    "    df_lugares = pd.DataFrame(places[:total_resultados])\n",
    "    return df_lugares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               nombre                                          direccion  \\\n",
      "0           Coworking                  Calle Bruc, 42, Calders Catalunya   \n",
      "1        IW Coworking  Carrer de Pau Claris, 90 (Gran Via de les Cort...   \n",
      "2        MG Coworking                     Bruc, 168, Barcelona Catalunya   \n",
      "3  Alparriuss Almazen    Consell de Cent, 523, 08013 Barcelona Catalunya   \n",
      "4       Itnig Coffice    Pujades, 100 (Alaba), 08005 Barcelona Catalunya   \n",
      "\n",
      "          categorias         coordenadas        tag  \n",
      "0  [Coworking Space]  41.391672,2.173255  coworking  \n",
      "1  [Coworking Space]  41.390296,2.170599  coworking  \n",
      "2  [Coworking Space]  41.398883,2.163654  coworking  \n",
      "3  [Coworking Space]  41.402324,2.180315  coworking  \n",
      "4  [Coworking Space]   41.396518,2.19417  coworking  \n"
     ]
    }
   ],
   "source": [
    "# Coordenadas de Barcelona\n",
    "barcelona_coords = \"41.3851,2.1734\"\n",
    "\n",
    "# Categor칤as: Coworking Space (11128), Coffee Shop (13032), Library (11135)\n",
    "categorias = \"11128,13032\"\n",
    "\n",
    "# Lista de queries (palabras clave) para buscar\n",
    "queries = [\"coworking\", \"Outdoor seating\"]\n",
    "\n",
    "# DataFrame vac칤o para combinar resultados\n",
    "df_combined = pd.DataFrame()\n",
    "\n",
    "# Bucle para realizar una b칰squeda por cada query y combinar los resultados\n",
    "for query in queries:\n",
    "    df_lugares = buscar_lugares_por_query(foursquare_api_key, barcelona_coords, query, categorias, limite=50, total_resultados=400)\n",
    "    df_combined = pd.concat([df_combined, df_lugares], ignore_index=True)\n",
    "\n",
    "# Eliminar duplicados basados en el nombre y direcci칩n, si es necesario\n",
    "df_combined.drop_duplicates(subset=['nombre', 'direccion'], inplace=True)\n",
    "\n",
    "# Mostrar los resultados combinados\n",
    "print(df_combined.head())\n",
    "\n",
    "# Guardar el DataFrame combinado en un archivo CSV si es necesario\n",
    "df_combined.to_csv('lugares_con_tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Extracci칩n de datos en OpenWeather API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperatura: 23.23춿C\n",
      "Humedad: 52%\n",
      "Descripci칩n del clima: few clouds\n"
     ]
    }
   ],
   "source": [
    "# Funci칩n para obtener datos clim치ticos usando la API de OpenWeather\n",
    "def obtener_clima(openweather_api_key, lat, lon):\n",
    "    \"\"\"\n",
    "    Obtiene datos clim치ticos actuales basados en latitud y longitud.\n",
    "    \n",
    "    Par치metros:\n",
    "    openweather_api_key (str): Clave API de OpenWeather.\n",
    "    lat (float): Latitud del lugar.\n",
    "    lon (float): Longitud del lugar.\n",
    "    \n",
    "    Retorna:\n",
    "    Un diccionario con los datos clim치ticos actuales.\n",
    "    \"\"\"\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={openweather_api_key}&units=metric\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Retorna los datos clim치ticos como un JSON\n",
    "    else:\n",
    "        print(f\"Error en la solicitud del clima: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Ejemplo de uso con las coordenadas de un lugar en Barcelona\n",
    "latitud = 41.3851  # Latitud de Barcelona\n",
    "longitud = 2.1734  # Longitud de Barcelona\n",
    "\n",
    "datos_climaticos = obtener_clima(openweather_api_key, latitud, longitud)\n",
    "\n",
    "if datos_climaticos:\n",
    "    # Extraer algunos datos importantes del clima\n",
    "    temperatura = datos_climaticos['main']['temp']\n",
    "    humedad = datos_climaticos['main']['humidity']\n",
    "    descripcion_clima = datos_climaticos['weather'][0]['description']\n",
    "    \n",
    "    print(f\"Temperatura: {temperatura}춿C\")\n",
    "    print(f\"Humedad: {humedad}%\")\n",
    "    print(f\"Descripci칩n del clima: {descripcion_clima}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Integraci칩n de los datos clim치ticos en los lugares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci칩n para agregar los datos clim치ticos a cada lugar\n",
    "def agregar_clima_a_lugares(df_lugares, openweather_api_key):\n",
    "    \"\"\"\n",
    "    Agrega datos clim치ticos a cada lugar en el DataFrame de lugares.\n",
    "    \n",
    "    Par치metros:\n",
    "    df_lugares (DataFrame): DataFrame con los lugares de trabajo.\n",
    "    openweather_api_key (str): Clave API de OpenWeather.\n",
    "    \n",
    "    Retorna:\n",
    "    Un nuevo DataFrame con la informaci칩n del clima agregada.\n",
    "    \"\"\"\n",
    "    # Listas para almacenar los datos clim치ticos\n",
    "    temperaturas = []\n",
    "    humedades = []\n",
    "    descripciones_clima = []\n",
    "    \n",
    "    # Iterar sobre cada lugar en el DataFrame\n",
    "    for index, row in df_lugares.iterrows():\n",
    "        latitud, longitud = row['coordenadas'].split(',')\n",
    "        latitud, longitud = float(latitud), float(longitud)\n",
    "        \n",
    "        # Obtener datos clim치ticos\n",
    "        clima = obtener_clima(openweather_api_key, latitud, longitud)\n",
    "        \n",
    "        if clima:\n",
    "            temperaturas.append(clima['main']['temp'])\n",
    "            humedades.append(clima['main']['humidity'])\n",
    "            descripciones_clima.append(clima['weather'][0]['description'])\n",
    "        else:\n",
    "            # Si hay un error al obtener el clima, agregar valores nulos\n",
    "            temperaturas.append(None)\n",
    "            humedades.append(None)\n",
    "            descripciones_clima.append(None)\n",
    "    \n",
    "    # Agregar las nuevas columnas al DataFrame de lugares\n",
    "    df_lugares['temperatura'] = temperaturas\n",
    "    df_lugares['humedad'] = humedades\n",
    "    df_lugares['descripcion_clima'] = descripciones_clima\n",
    "    \n",
    "    return df_lugares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               nombre                                          direccion  \\\n",
      "0           Coworking                  Calle Bruc, 42, Calders Catalunya   \n",
      "1        IW Coworking  Carrer de Pau Claris, 90 (Gran Via de les Cort...   \n",
      "2        MG Coworking                     Bruc, 168, Barcelona Catalunya   \n",
      "3  Alparriuss Almazen    Consell de Cent, 523, 08013 Barcelona Catalunya   \n",
      "4       Itnig Coffice    Pujades, 100 (Alaba), 08005 Barcelona Catalunya   \n",
      "\n",
      "          categorias         coordenadas        tag  temperatura  humedad  \\\n",
      "0  [Coworking Space]  41.391672,2.173255  coworking        23.23       52   \n",
      "1  [Coworking Space]  41.390296,2.170599  coworking        23.23       52   \n",
      "2  [Coworking Space]  41.398883,2.163654  coworking        23.00       53   \n",
      "3  [Coworking Space]  41.402324,2.180315  coworking        23.17       52   \n",
      "4  [Coworking Space]   41.396518,2.19417  coworking        23.30       53   \n",
      "\n",
      "  descripcion_clima  \n",
      "0        few clouds  \n",
      "1        few clouds  \n",
      "2        few clouds  \n",
      "3        few clouds  \n",
      "4        few clouds  \n"
     ]
    }
   ],
   "source": [
    "# Integrar el clima en el DataFrame de lugares\n",
    "df_lugares_clima = agregar_clima_a_lugares(df_combined, openweather_api_key)\n",
    "\n",
    "# Mostrar los primeros resultados con el clima incluido\n",
    "print(df_lugares_clima.head())\n",
    "\n",
    "# Guardar el DataFrame combinado con el clima en un archivo CSV\n",
    "df_lugares_clima.to_csv('lugares_con_clima.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>direccion</th>\n",
       "      <th>categorias</th>\n",
       "      <th>coordenadas</th>\n",
       "      <th>tag</th>\n",
       "      <th>temperatura</th>\n",
       "      <th>humedad</th>\n",
       "      <th>descripcion_clima</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coworking</td>\n",
       "      <td>Calle Bruc, 42, Calders Catalunya</td>\n",
       "      <td>[Coworking Space]</td>\n",
       "      <td>41.391672,2.173255</td>\n",
       "      <td>coworking</td>\n",
       "      <td>23.23</td>\n",
       "      <td>52</td>\n",
       "      <td>few clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IW Coworking</td>\n",
       "      <td>Carrer de Pau Claris, 90 (Gran Via de les Cort...</td>\n",
       "      <td>[Coworking Space]</td>\n",
       "      <td>41.390296,2.170599</td>\n",
       "      <td>coworking</td>\n",
       "      <td>23.23</td>\n",
       "      <td>52</td>\n",
       "      <td>few clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MG Coworking</td>\n",
       "      <td>Bruc, 168, Barcelona Catalunya</td>\n",
       "      <td>[Coworking Space]</td>\n",
       "      <td>41.398883,2.163654</td>\n",
       "      <td>coworking</td>\n",
       "      <td>23.00</td>\n",
       "      <td>53</td>\n",
       "      <td>few clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alparriuss Almazen</td>\n",
       "      <td>Consell de Cent, 523, 08013 Barcelona Catalunya</td>\n",
       "      <td>[Coworking Space]</td>\n",
       "      <td>41.402324,2.180315</td>\n",
       "      <td>coworking</td>\n",
       "      <td>23.17</td>\n",
       "      <td>52</td>\n",
       "      <td>few clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Itnig Coffice</td>\n",
       "      <td>Pujades, 100 (Alaba), 08005 Barcelona Catalunya</td>\n",
       "      <td>[Coworking Space]</td>\n",
       "      <td>41.396518,2.19417</td>\n",
       "      <td>coworking</td>\n",
       "      <td>23.30</td>\n",
       "      <td>53</td>\n",
       "      <td>few clouds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               nombre                                          direccion  \\\n",
       "0           Coworking                  Calle Bruc, 42, Calders Catalunya   \n",
       "1        IW Coworking  Carrer de Pau Claris, 90 (Gran Via de les Cort...   \n",
       "2        MG Coworking                     Bruc, 168, Barcelona Catalunya   \n",
       "3  Alparriuss Almazen    Consell de Cent, 523, 08013 Barcelona Catalunya   \n",
       "4       Itnig Coffice    Pujades, 100 (Alaba), 08005 Barcelona Catalunya   \n",
       "\n",
       "          categorias         coordenadas        tag  temperatura  humedad  \\\n",
       "0  [Coworking Space]  41.391672,2.173255  coworking        23.23       52   \n",
       "1  [Coworking Space]  41.390296,2.170599  coworking        23.23       52   \n",
       "2  [Coworking Space]  41.398883,2.163654  coworking        23.00       53   \n",
       "3  [Coworking Space]  41.402324,2.180315  coworking        23.17       52   \n",
       "4  [Coworking Space]   41.396518,2.19417  coworking        23.30       53   \n",
       "\n",
       "  descripcion_clima  \n",
       "0        few clouds  \n",
       "1        few clouds  \n",
       "2        few clouds  \n",
       "3        few clouds  \n",
       "4        few clouds  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lugares_clima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 2. Obtener datos con Web Scraping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El auge de los **K-Dramas** ha generado una gran comunidad de seguidores que buscan constantemente nuevas series que se ajusten a sus gustos. Sin embargo, con la creciente cantidad de contenido disponible, puede ser complicado elegir qu칠 K-Drama ver a continuaci칩n. Por ello, este proyecto tiene como objetivo crear un DataFrame con informaci칩n detallada de K-Dramas, incluyendo t칤tulo, calificaci칩n, g칠neros, director, protagonistas y n칰mero de espectadores, con el prop칩sito de desarrollar en el futuro una plataforma de recomendaci칩n personalizada de K-Dramas.\n",
    "\n",
    "La idea es que, mediante el an치lisis de estos datos y el uso de la informaci칩n proporcionada por los usuarios (como preferencias de g칠neros o actores favoritos), se pueda crear un sistema de recomendaciones que sugiere K-Dramas que encajen con los gustos individuales. Este proyecto sentar치 las bases para la creaci칩n de dicha plataforma, al extraer datos relevantes a trav칠s de t칠cnicas de Web Scraping de sitios especializados, como MyDramaList.\n",
    "\n",
    "**En esta primera fase, el scraping de K-Dramas permitir치 generar un dataset estructurado con los siguientes campos:**\n",
    "\n",
    "- T칤tulo del K-Drama\n",
    "- Calificaci칩n (Rating)\n",
    "- G칠neros (Genres)\n",
    "- Director\n",
    "- Protagonistas (Main Cast)\n",
    "- N칰mero de espectadores (# of Watchers)\n",
    "\n",
    "Este dataset no solo permitir치 a los fan치ticos de los K-Dramas explorar opciones, sino que tambi칠n abrir치 las puertas a la implementaci칩n de algoritmos de recomendaci칩n en funci칩n de los gustos y preferencias de los usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias a utilizar\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1: Extraer URLs de K-dramas de varias p치ginas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Primero se realizar치 la prueba para una pagina, luego se iterara. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_lista_kdramas(pagina=1):\n",
    "    url = f\"https://mydramalist.com/shows/top?page={pagina}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    kdramas = []\n",
    "    \n",
    "    # Acceder a los K-dramas listados en la p치gina\n",
    "    for kdrama in soup.find_all(\"div\", class_=\"box\"):\n",
    "        # Extraer el t칤tulo\n",
    "        titulo = kdrama.find(\"h6\", class_=\"text-primary title\").text.strip() if kdrama.find(\"h6\", class_=\"text-primary title\") else \"No disponible\"\n",
    "        \n",
    "        # Extraer la calificaci칩n\n",
    "        calificacion = kdrama.find(\"span\", class_=\"p-1-xs score\").text.strip() if kdrama.find(\"span\", class_=\"p-1-xs score\") else \"No disponible\"\n",
    "        \n",
    "        # Extraer la URL del K-drama\n",
    "        enlace = kdrama.find(\"a\")\n",
    "        url_kdrama = \"https://mydramalist.com\" + enlace[\"href\"] if enlace and \"href\" in enlace.attrs else \"No disponible\"\n",
    "        \n",
    "        # A침adir los datos del K-drama a la lista\n",
    "        kdramas.append({\"T칤tulo\": titulo, \"Calificaci칩n\": calificacion, \"URL\": url_kdrama})\n",
    "    \n",
    "    return kdramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'T칤tulo': 'Twinkling Watermelon', 'Calificaci칩n': 'No disponible', 'URL': 'https://mydramalist.com/739603-sparkling-watermelon'}, {'T칤tulo': 'Move to Heaven', 'Calificaci칩n': 'No disponible', 'URL': 'https://mydramalist.com/49231-move-to-heaven'}, {'T칤tulo': 'Hospital Playlist Season 2', 'Calificaci칩n': 'No disponible', 'URL': 'https://mydramalist.com/57173-hospital-playlist-2'}, {'T칤tulo': 'Weak Hero Class 1', 'Calificaci칩n': 'No disponible', 'URL': 'https://mydramalist.com/702267-weak-hero'}, {'T칤tulo': 'Nirvana in Fire', 'Calificaci칩n': 'No disponible', 'URL': 'https://mydramalist.com/9025-nirvana-in-fire'}]\n"
     ]
    }
   ],
   "source": [
    "# Probar la funci칩n\n",
    "lista_kdramas = obtener_lista_kdramas(pagina=1)\n",
    "\n",
    "# Verificar si la lista fue extra칤da correctamente\n",
    "if lista_kdramas is not None:\n",
    "    # Mostrar los primeros registros para verificar\n",
    "    print(lista_kdramas[:5])\n",
    "else:\n",
    "    print(\"No se pudo obtener la lista de K-dramas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Para 10 paginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci칩n para obtener la lista de URLs de K-dramas desde varias p치ginas\n",
    "def obtener_urls_kdramas(num_paginas=10):\n",
    "    base_url = \"https://mydramalist.com/shows/top?page={}\"\n",
    "    urls_kdramas = []\n",
    "\n",
    "    for pagina in range(1, num_paginas + 1):\n",
    "        url = base_url.format(pagina)\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extraer todas las URLs de los K-dramas de la p치gina\n",
    "        for kdrama in soup.find_all('h6', class_='text-primary title'):\n",
    "            kdrama_url = \"https://mydramalist.com\" + kdrama.find('a')['href']\n",
    "            urls_kdramas.append(kdrama_url)\n",
    "    \n",
    "    return urls_kdramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han extra칤do 200 URLs de K-dramas.\n"
     ]
    }
   ],
   "source": [
    "# Probar la funci칩n para obtener las URLs de los K-dramas de 10 p치ginas\n",
    "urls = obtener_urls_kdramas(num_paginas=10)\n",
    "print(f\"Se han extra칤do {len(urls)} URLs de K-dramas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://mydramalist.com/739603-sparkling-watermelon', 'https://mydramalist.com/49231-move-to-heaven', 'https://mydramalist.com/57173-hospital-playlist-2', 'https://mydramalist.com/702267-weak-hero', 'https://mydramalist.com/9025-nirvana-in-fire', 'https://mydramalist.com/52939-can-this-person-be-translated', 'https://mydramalist.com/54625-flower-of-evil', 'https://mydramalist.com/25560-moving', 'https://mydramalist.com/36269-doctor-playbook', 'https://mydramalist.com/750099-time-walking-on-memory', 'https://mydramalist.com/13544-reply-1988', 'https://mydramalist.com/697563-kai-duan', 'https://mydramalist.com/28674-joy-of-life', 'https://mydramalist.com/713331-the-lotus-casebook', 'https://mydramalist.com/2-1-litre-no-namida', 'https://mydramalist.com/25172-my-ajusshi', 'https://mydramalist.com/729705-hidden-love', 'https://mydramalist.com/28723-the-untamed', 'https://mydramalist.com/62295-luo-yao-knew-what-he-meant', 'https://mydramalist.com/54083-joy-of-life-season-2', 'https://mydramalist.com/705857-umbrella', 'https://mydramalist.com/729363-love-like-the-galaxy-part-2', 'https://mydramalist.com/35729-emergency-lands-of-love', 'https://mydramalist.com/745581-the-glory-season-2', 'https://mydramalist.com/687167-xing-han-can-lan', 'https://mydramalist.com/58365-queen-cheorin', 'https://mydramalist.com/730629-bu-liang-zhi-nian-qing-chu-shi', 'https://mydramalist.com/22624-wise-prison-life', 'https://mydramalist.com/21308-mother', 'https://mydramalist.com/39715-some-day-or-one-day', 'https://mydramalist.com/733821-lovers', 'https://mydramalist.com/711113-dr-romantic-3', 'https://mydramalist.com/40911-go-ahead', 'https://mydramalist.com/49865-psycho-but-it-s-okay', 'https://mydramalist.com/685237-untitled-kim-eun-sook-project', 'https://mydramalist.com/733261-alchemy-of-souls-part-2', 'https://mydramalist.com/705723-strange-lawyer-woo-young-woo', 'https://mydramalist.com/755309-my-dearest-part-2', 'https://mydramalist.com/681049-death-kaleidoscope', 'https://mydramalist.com/59381-navillera', 'https://mydramalist.com/13239-signal', 'https://mydramalist.com/61371-vincenzo', 'https://mydramalist.com/683119-shao-nian-ge-xing', 'https://mydramalist.com/733003-bad-mother', 'https://mydramalist.com/756633-i-feel-you-linger-in-the-air-uncut-version', 'https://mydramalist.com/705589-taxi-driver-2', 'https://mydramalist.com/32220-kingdom-2', 'https://mydramalist.com/761313-death-s-game-part-2', 'https://mydramalist.com/23920-mr.-sunshine', 'https://mydramalist.com/736749-di-jia-qian-jin', 'https://mydramalist.com/690709-happiness', 'https://mydramalist.com/733445-i-will-die-soon', 'https://mydramalist.com/45437-qi-hun', 'https://mydramalist.com/684373-imawa-no-kuni-no-alice-2', 'https://mydramalist.com/695963-tomorrow', 'https://mydramalist.com/715585-you-feng-de-di-fang', 'https://mydramalist.com/58953-mouse', 'https://mydramalist.com/39537-imawa-no-kuni-no-arisu', 'https://mydramalist.com/58781-more-than-blue', 'https://mydramalist.com/23911-the-story-of-ming-lan', 'https://mydramalist.com/10814-healer', 'https://mydramalist.com/18452-goblin', 'https://mydramalist.com/712521-tale-of-the-nine-tailed-season-2', 'https://mydramalist.com/53117-cang-lan-jue', 'https://mydramalist.com/748473-one-piece', 'https://mydramalist.com/695149-twenty-five-twenty-one', 'https://mydramalist.com/52921-model-taxi', 'https://mydramalist.com/62085-a-wonderful-rumor', 'https://mydramalist.com/59001-d-p-dog-day', 'https://mydramalist.com/21934-stranger', 'https://mydramalist.com/28565-the-tale-of-yanxi-palace', 'https://mydramalist.com/725367-untitled-park-ji-eun-project', 'https://mydramalist.com/16547-eternal-love', 'https://mydramalist.com/22806-kingdom', 'https://mydramalist.com/61399-dress-sleeved-red', 'https://mydramalist.com/753495-love-supremacy-zone', 'https://mydramalist.com/696751-missing-the-other-side-2', 'https://mydramalist.com/19262-weightlifting-fairy-kim-bok-joo', 'https://mydramalist.com/720737-morning-comes-to-the-mental-ward', 'https://mydramalist.com/30740-sky-castle', 'https://mydramalist.com/744135-the-killer-s-shopping-mall', 'https://mydramalist.com/59487-sword-snow-stride', 'https://mydramalist.com/38301-romantic-doctor-teacher-kim-2', 'https://mydramalist.com/70249-lie-zui-tu-jian', 'https://mydramalist.com/74275-youth-of-may', 'https://mydramalist.com/62573-blue-sky', 'https://mydramalist.com/749431-the-story-of-hua-zhi', 'https://mydramalist.com/697861-yu-feng-xing', 'https://mydramalist.com/60911-monster', 'https://mydramalist.com/62337-you-are-my-glory', 'https://mydramalist.com/699557-inside-criminal-minds', 'https://mydramalist.com/719227-ning-an-ru-meng', 'https://mydramalist.com/682545-hatsukoi', 'https://mydramalist.com/746529-skz-flix', 'https://mydramalist.com/15845-dear-my-friends', 'https://mydramalist.com/66507-the-outcast', 'https://mydramalist.com/75433-rocket-boy-squad', 'https://mydramalist.com/62087-the-demon-judge', 'https://mydramalist.com/32917-partners-for-justice-2', 'https://mydramalist.com/34667-arthdal-chronicles-season-3', 'https://mydramalist.com/15999-moon-lovers-scarlet-heart-ryeo', 'https://mydramalist.com/26949-life-on-mars', 'https://mydramalist.com/683929-mr-hong', 'https://mydramalist.com/39661-love-and-redemption', 'https://mydramalist.com/731967-a-journey-to-love', 'https://mydramalist.com/34665-arthdal-chronicles-season-2', 'https://mydramalist.com/14324-six-flying-dragons', 'https://mydramalist.com/729833-thai-cave-rescue', 'https://mydramalist.com/34064-sweet-home', 'https://mydramalist.com/702507-mystery-to-iunakare', 'https://mydramalist.com/28686-hand', 'https://mydramalist.com/20566-nirvana-in-fire-2-the-wind-blows-in-chang-lin', 'https://mydramalist.com/748325-my-aletai', 'https://mydramalist.com/18894-strong-woman-do-bong-soon', 'https://mydramalist.com/21576-while-you-were-sleeping', 'https://mydramalist.com/713549-d-p-season-2', 'https://mydramalist.com/53535-penthouse', 'https://mydramalist.com/680959-the-penthouse-season-2', 'https://mydramalist.com/19684-defendant', 'https://mydramalist.com/65391-nemesis', 'https://mydramalist.com/711391-the-police-station-next-to-fire-station', 'https://mydramalist.com/699597-king-of-pigs', 'https://mydramalist.com/10873-kill-me-heal-me', 'https://mydramalist.com/19510-romantic-doctor-teacher-kim', 'https://mydramalist.com/746193-gold-spoon', 'https://mydramalist.com/51397-final-chronicles', 'https://mydramalist.com/693591-in-house-confrontation', 'https://mydramalist.com/263-jewel-in-the-palace', 'https://mydramalist.com/33075-strangers-from-hell', 'https://mydramalist.com/717539-the-devil', 'https://mydramalist.com/694231-us-that-year', 'https://mydramalist.com/52941-eighteen-again', 'https://mydramalist.com/53953-princess-changge', 'https://mydramalist.com/54851-try-the-world', 'https://mydramalist.com/717895-if-there-is-still-time-left', 'https://mydramalist.com/700341-qing-chuan-daily-life', 'https://mydramalist.com/10619-incomplete-life', 'https://mydramalist.com/25422-unnatural', 'https://mydramalist.com/22403-chicago-typewriter', 'https://mydramalist.com/701881-hounds', 'https://mydramalist.com/63781-love-your-bones-forever-2', 'https://mydramalist.com/718187-day-of-kidnapping', 'https://mydramalist.com/697585-our-blues', 'https://mydramalist.com/44985-lost-you-forever', 'https://mydramalist.com/53101-missing', 'https://mydramalist.com/68429-the-lighter-and-the-princess-gown', 'https://mydramalist.com/39221-stove-league', 'https://mydramalist.com/21687-tunnel', 'https://mydramalist.com/723885-the-worst-evil', 'https://mydramalist.com/32018-3-nen-a-gumi-ima-kara-minna-san-wa-hitojichi-desu', 'https://mydramalist.com/10904-descendants-of-the-sun', 'https://mydramalist.com/7125-hanzawa-naoki', 'https://mydramalist.com/29565-hot-blooded-priest', 'https://mydramalist.com/31618-winter-begonia', 'https://mydramalist.com/51571-cat-s-cradle', 'https://mydramalist.com/312-mother', 'https://mydramalist.com/49241-falling-into-your-smile', 'https://mydramalist.com/32925-hotel-del-luna', 'https://mydramalist.com/719347-bumped-into-you', 'https://mydramalist.com/5591-battle-of-changsha', 'https://mydramalist.com/30867-special-forces', 'https://mydramalist.com/693513-hei-yue-guang-wen-na-be-ju-ben', 'https://mydramalist.com/49877-love-to-be-loved-by-you', 'https://mydramalist.com/9289-its-okay-thats-love', 'https://mydramalist.com/743267-welcome-to-samdalri', 'https://mydramalist.com/24015-live', 'https://mydramalist.com/62623-law-school', 'https://mydramalist.com/758139-ossan-s-love-returns', 'https://mydramalist.com/30967-red-moon-blue-sea', 'https://mydramalist.com/24685-project-s-the-series-skate-our-souls', 'https://mydramalist.com/33767-crossfire', 'https://mydramalist.com/749923-pyramid-game', 'https://mydramalist.com/44611-i-have-been-there-once', 'https://mydramalist.com/23472-bpoop-phaeh-saniwaat', 'https://mydramalist.com/52897-lovely-us', 'https://mydramalist.com/737063-half-of-us', 'https://mydramalist.com/6068-kazoku-game-2013', 'https://mydramalist.com/702919-during-the-snowstorm', 'https://mydramalist.com/762521-shogun', 'https://mydramalist.com/685441-an-untitled-jtbc-project', 'https://mydramalist.com/688213-ghost-doctor', 'https://mydramalist.com/79997-boy-referee', 'https://mydramalist.com/26644-eulachacha-waikiki', 'https://mydramalist.com/704081-snow-white-must-die', 'https://mydramalist.com/59021-tian-ya-ke', 'https://mydramalist.com/743381-brush-up-life', 'https://mydramalist.com/26385-three-lives-three-worlds-the-pillow-book', 'https://mydramalist.com/7114-empress-ki', 'https://mydramalist.com/23281-heavy-sweetness-ash-like-frost', 'https://mydramalist.com/27367-the-gifted', 'https://mydramalist.com/24863-go-back-couple', 'https://mydramalist.com/749903-i-a-gangster-became-a-high-schooler', 'https://mydramalist.com/38907-the-third-princess-from-the-rumors', 'https://mydramalist.com/12252-tenno-no-ryoriban', 'https://mydramalist.com/20340-good-manager', 'https://mydramalist.com/56519-miu-404', 'https://mydramalist.com/3394-the-bridal-mask', 'https://mydramalist.com/27361-stranger-2', 'https://mydramalist.com/8507-boku-no-ita-jikan', 'https://mydramalist.com/748283-confidential-items']\n"
     ]
    }
   ],
   "source": [
    "print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Extraer la informaci칩n detallada de cada K-drama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.Prueba para un kdrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci칩n para extraer informaci칩n de un K-Drama desde una p치gina\n",
    "def extraer_info_kdrama(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # T칤tulo\n",
    "    title_tag = soup.find('h1', class_='film-title')\n",
    "    title = title_tag.text.strip() if title_tag else \"No disponible\"\n",
    "\n",
    "    # Calificaci칩n (rating)\n",
    "    rating_tag = soup.find('div', class_='hfs')\n",
    "    rating = rating_tag.find('b').text if rating_tag else \"No disponible\"\n",
    "\n",
    "    # Espectadores (Watchers)\n",
    "    watcher = \"No disponible\"\n",
    "    watchers_divs = soup.find_all('div', class_='hfs')\n",
    "    for div in watchers_divs:\n",
    "        if '# of Watchers:' in div.text:\n",
    "            watcher = div.find('b').text.strip()\n",
    "            break\n",
    "\n",
    "    # G칠neros\n",
    "    genres_tag = soup.find('li', class_='show-genres')\n",
    "    genres = ', '.join([genre.text.strip() for genre in genres_tag.find_all('a')]) if genres_tag else \"No disponible\"\n",
    "\n",
    "    return {\n",
    "        'T칤tulo': title,\n",
    "        'Calificaci칩n': rating,\n",
    "        'G칠neros': genres,\n",
    "        'Espectadores': watcher\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T칤tulo': 'Twinkling Watermelon (2023)', 'Calificaci칩n': '9.2', 'G칠neros': 'Romance, Youth, Drama, Fantasy', 'Espectadores': '86,749'}\n"
     ]
    }
   ],
   "source": [
    "# Probar la funci칩n con una URL espec칤fica\n",
    "detalles_kdrama = extraer_info_kdrama(\"https://mydramalist.com/739603-sparkling-watermelon\")\n",
    "\n",
    "# Mostrar los detalles obtenidos\n",
    "print(detalles_kdrama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Extraer informacion de varios Kdrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con la informaci칩n de los K-dramas\n",
    "def crear_dataframe_kdramas(urls):\n",
    "    kdramas_data = []\n",
    "    \n",
    "    for url in urls:\n",
    "        info_kdrama = extraer_info_kdrama(url)\n",
    "        kdramas_data.append(info_kdrama)\n",
    "    \n",
    "    df = pd.DataFrame(kdramas_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Crear Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              T칤tulo Calificaci칩n  \\\n",
      "0        Twinkling Watermelon (2023)          9.2   \n",
      "1              Move to Heaven (2021)          9.1   \n",
      "2  Hospital Playlist Season 2 (2021)          9.1   \n",
      "3           Weak Hero Class 1 (2022)          9.1   \n",
      "4             Nirvana in Fire (2015)          9.1   \n",
      "\n",
      "                                  G칠neros Espectadores  \n",
      "0          Romance, Youth, Drama, Fantasy       86,749  \n",
      "1                             Life, Drama      105,409  \n",
      "2           Romance, Life, Drama, Medical       71,742  \n",
      "3                    Action, Youth, Drama       92,750  \n",
      "4  Military, Historical, Drama, Political       38,806  \n"
     ]
    }
   ],
   "source": [
    "df_kdramas = crear_dataframe_kdramas(urls)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(df_kdramas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T칤tulo</th>\n",
       "      <th>Calificaci칩n</th>\n",
       "      <th>G칠neros</th>\n",
       "      <th>Espectadores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twinkling Watermelon (2023)</td>\n",
       "      <td>9.2</td>\n",
       "      <td>Romance, Youth, Drama, Fantasy</td>\n",
       "      <td>86,749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Move to Heaven (2021)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Life, Drama</td>\n",
       "      <td>105,409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hospital Playlist Season 2 (2021)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Romance, Life, Drama, Medical</td>\n",
       "      <td>71,742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weak Hero Class 1 (2022)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Action, Youth, Drama</td>\n",
       "      <td>92,750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nirvana in Fire (2015)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Military, Historical, Drama, Political</td>\n",
       "      <td>38,806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alchemy of Souls (2022)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Action, Historical, Romance, Fantasy</td>\n",
       "      <td>118,871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Flower of Evil (2020)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Thriller, Romance, Crime, Melodrama</td>\n",
       "      <td>144,431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Moving (2023)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Action, Thriller, Mystery, Supernatural</td>\n",
       "      <td>68,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hospital Playlist (2020)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Friendship, Comedy, Life, Drama, Medical</td>\n",
       "      <td>113,356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lovely Runner (2024)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Music, Comedy, Romance, Fantasy</td>\n",
       "      <td>80,316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Reply 1988 (2015)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Comedy, Romance, Life, Youth</td>\n",
       "      <td>118,002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Reset (2022)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Thriller, Mystery, Sci-Fi</td>\n",
       "      <td>40,982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Joy of Life (2019)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Mystery, Romance, Wuxia, Fantasy</td>\n",
       "      <td>29,623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mysterious Lotus Casebook (2023)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Mystery, Wuxia</td>\n",
       "      <td>19,111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1 Litre no Namida (2005)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Romance, Drama, Melodrama</td>\n",
       "      <td>41,471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>My Mister (2018)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Psychological, Life, Drama</td>\n",
       "      <td>81,439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hidden Love (2023)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Comedy, Romance, Life, Youth</td>\n",
       "      <td>85,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Untamed (2019)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Mystery, Wuxia, Fantasy</td>\n",
       "      <td>104,450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>When I Fly Towards You (2023)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Comedy, Romance, Youth</td>\n",
       "      <td>51,458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Joy of Life Season 2 (2024)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Comedy, Romance, Wuxia, Fantasy</td>\n",
       "      <td>10,318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               T칤tulo Calificaci칩n  \\\n",
       "0         Twinkling Watermelon (2023)          9.2   \n",
       "1               Move to Heaven (2021)          9.1   \n",
       "2   Hospital Playlist Season 2 (2021)          9.1   \n",
       "3            Weak Hero Class 1 (2022)          9.1   \n",
       "4              Nirvana in Fire (2015)          9.1   \n",
       "5             Alchemy of Souls (2022)          9.1   \n",
       "6               Flower of Evil (2020)          9.1   \n",
       "7                       Moving (2023)          9.1   \n",
       "8            Hospital Playlist (2020)          9.1   \n",
       "9                Lovely Runner (2024)          9.0   \n",
       "10                  Reply 1988 (2015)          9.1   \n",
       "11                       Reset (2022)          9.0   \n",
       "12                 Joy of Life (2019)          9.0   \n",
       "13   Mysterious Lotus Casebook (2023)          9.0   \n",
       "14           1 Litre no Namida (2005)          9.0   \n",
       "15                   My Mister (2018)          9.0   \n",
       "16                 Hidden Love (2023)          9.0   \n",
       "17                 The Untamed (2019)          9.0   \n",
       "18      When I Fly Towards You (2023)          9.0   \n",
       "19        Joy of Life Season 2 (2024)          9.0   \n",
       "\n",
       "                                     G칠neros Espectadores  \n",
       "0             Romance, Youth, Drama, Fantasy       86,749  \n",
       "1                                Life, Drama      105,409  \n",
       "2              Romance, Life, Drama, Medical       71,742  \n",
       "3                       Action, Youth, Drama       92,750  \n",
       "4     Military, Historical, Drama, Political       38,806  \n",
       "5       Action, Historical, Romance, Fantasy      118,871  \n",
       "6        Thriller, Romance, Crime, Melodrama      144,431  \n",
       "7    Action, Thriller, Mystery, Supernatural       68,290  \n",
       "8   Friendship, Comedy, Life, Drama, Medical      113,356  \n",
       "9            Music, Comedy, Romance, Fantasy       80,316  \n",
       "10              Comedy, Romance, Life, Youth      118,002  \n",
       "11                 Thriller, Mystery, Sci-Fi       40,982  \n",
       "12          Mystery, Romance, Wuxia, Fantasy       29,623  \n",
       "13                            Mystery, Wuxia       19,111  \n",
       "14                 Romance, Drama, Melodrama       41,471  \n",
       "15                Psychological, Life, Drama       81,439  \n",
       "16              Comedy, Romance, Life, Youth       85,300  \n",
       "17                   Mystery, Wuxia, Fantasy      104,450  \n",
       "18                    Comedy, Romance, Youth       51,458  \n",
       "19           Comedy, Romance, Wuxia, Fantasy       10,318  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kdramas.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame combinado con el clima en un archivo CSV\n",
    "df_kdramas.to_csv('kdrama_database.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
