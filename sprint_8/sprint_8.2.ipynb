{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightgray; color:black; padding:10px; border-radius:5px;\">\n",
    "  <h1>Sprint 8</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 8: Entrena los modelos de tu proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 **Objetivo:**\n",
    "Entrenar los modelos al dataset analizado en el sprint 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 1**. Entrenar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "En estudios previos, se realizó un análisis exploratorio de datos (EDA) que permitió obtener una comprensión detallada de las características del conjunto de datos. Este análisis identificó variables categóricas y numéricas, reveló patrones clave y estableció las necesidades de preprocesamiento esenciales para optimizar su uso en modelos predictivos. A continuación, se resumen los principales hallazgos:\n",
    "\n",
    "**Clasificación de las Variables:**\n",
    "* Numéricas: Identificación de variables con asimetrías, curtosis y outliers (balance, duration, campaign, pdays, previous).\n",
    "* Categóricas: Clasificación en nominales y ordinales (education, month, job, entre otras).\n",
    "\n",
    "**Tratamiento de Variables Numéricas:**\n",
    "* Outliers: Winsorización aplicada para mitigar el impacto de valores extremos.\n",
    "* Transformación logarítmica: Usada en variables con distribuciones altamente sesgadas.\n",
    "* Escalado: RobustScaler para variables con outliers y MinMaxScaler para las demás.\n",
    "\n",
    "**Imputación de Valores Faltantes:**\n",
    "* Numéricas: Imputación con la mediana.\n",
    "* Categóricas: Imputación con \"unknown\" para mantener coherencia.\n",
    "\n",
    "**Codificación de Variables Categóricas:**\n",
    "* Ordinales: Codificación con valores específicos para reflejar orden lógico (education, month).\n",
    "* Nominales: One-Hot Encoding aplicado con eliminación de la columna de referencia para reducir dimensionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo de este Estudio\n",
    "En este proyecto, se busca implementar un modelo de clasificación, específicamente una **Regresión Logística**, que permita predecir la probabilidad de que un cliente suscriba un depósito bancario. Para ello, se empleará una pipeline que automatice el preprocesamiento de los datos, asegurando la reproducibilidad de las transformaciones realizadas en los estudios previos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enfoque Metodológico\n",
    "\n",
    "* Pipeline de Transformaciones: Construir una pipeline que integre las imputaciones, transformaciones logarítmicas, winsorización, escalado y codificación de variables. Esto garantizará un flujo estructurado y replicable del preprocesamiento.\n",
    "\n",
    "* Entrenamiento del Modelo:\n",
    "    - Dividir los datos en conjuntos de entrenamiento y prueba mediante estratificación para mantener la distribución de la variable objetivo.\n",
    "    - Entrenar el modelo de Regresión Logística utilizando los datos preprocesados.\n",
    "\n",
    "* Evaluación y Métricas:\n",
    "    - Evaluar el modelo mediante métricas clave como accuracy, f1-score, roc-auc, precisión y recall.\n",
    "    - Generar una matriz de confusión para analizar los errores en la clasificación de las clases.\n",
    "\n",
    "* Optimización: Ajustar los hiperparámetros del modelo para mejorar su desempeño.\n",
    "\n",
    "* Interpretación y Comparación: Analizar los coeficientes del modelo para identificar las variables más influyentes y comparar los resultados obtenidos con los objetivos del negocio.\n",
    "\n",
    "* Guardado para Productivización: Al finalizar, guardar la pipeline y el modelo entrenado para su uso en producción mediante herramientas como Streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, RobustScaler, MinMaxScaler, FunctionTransformer\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, f1_score, accuracy_score,  make_scorer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Carga el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data= pd.read_csv('/home/ngonzalez/mi_pagina_personal/bank_dataset.CSV')\n",
    "bank_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Informació general del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploración inicial del DataFrame\n",
    "bank_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método data.info() nos proporciona un resumen general del conjunto de datos:\n",
    "\n",
    "- Total de entradas: 11,162 registros con 17 columnas.\n",
    "Tipos de datos:\n",
    "- Variables numéricas (de tipo float64 y int64): como age, balance, day, duration, campaign, pdays, previous.\n",
    "- Variables categóricas (object): job, marital, education, default, housing, loan, contact, month, poutcome, y deposit.\n",
    "- Valores faltantes:age, marital, y education tienen algunos valores faltantes, ya manejados previamente en el análisis.\n",
    "\n",
    "Este resumen nos confirma que las variables están bien definidas para el análisis exploratorio y el modelado posterior, permitiendo un análisis demográfico, financiero y de interacción de los clientes en relación con la suscripción de depósitos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Crear Pipeline de Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificación de variables\n",
    "ordinal_features = ['education', 'month']\n",
    "ordinal_orders = {\n",
    "    'education': ['unknown', 'primary', 'secondary', 'tertiary'],\n",
    "    'month': ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "}\n",
    "\n",
    "nominal_features = ['job', 'marital', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "low_freq_features = ['job', 'contact', 'poutcome']\n",
    "\n",
    "# Variables numéricas\n",
    "outlier_features = ['balance', 'duration', 'pdays']\n",
    "non_outlier_features = ['age', 'campaign', 'previous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de Winsorización\n",
    "# Función para aplicar winsorización\n",
    "def winsorize_transform(X):\n",
    "    return np.apply_along_axis(lambda col: winsorize(col, limits=[0.05, 0.05]), axis=0, arr=X)\n",
    "\n",
    "# Función para transformación logarítmica\n",
    "def log_transform(X):\n",
    "    X = np.where(X <= 0, X + np.abs(X.min(axis=0)) + 1, X)  # Ajustar valores negativos o cero\n",
    "    return np.log1p(X)\n",
    "\n",
    "class LowFrequencyGrouper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.05):\n",
    "        self.threshold = threshold\n",
    "        self.low_freq_categories_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calcular categorías de baja frecuencia para cada columna\n",
    "        self.low_freq_categories_ = []\n",
    "        for col in range(X.shape[1]):\n",
    "            unique, counts = np.unique(X[:, col], return_counts=True)\n",
    "            freq = counts / len(X)\n",
    "            low_freq_categories = unique[freq < self.threshold]\n",
    "            self.low_freq_categories_.append(low_freq_categories)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Reemplazar categorías de baja frecuencia por 'Otros'\n",
    "        X_transformed = X.copy()\n",
    "        for col in range(X.shape[1]):\n",
    "            low_freq_categories = self.low_freq_categories_[col]\n",
    "            X_transformed[:, col] = np.where(\n",
    "                np.isin(X_transformed[:, col], low_freq_categories), 'Otros', X_transformed[:, col]\n",
    "            )\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines individuales\n",
    "# 1. Para variables ordinales\n",
    "ordinal_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('ordinal_encoder', OrdinalEncoder(categories=[ordinal_orders[feature] for feature in ordinal_features]))\n",
    "])\n",
    "\n",
    "# 2. Para variables nominales con agrupamiento de baja frecuencia\n",
    "nominal_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('low_freq_grouper', LowFrequencyGrouper(threshold=0.05)),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False))\n",
    "])\n",
    "\n",
    "# 3. Para variables numéricas con outliers\n",
    "outlier_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('winsorizer', FunctionTransformer(winsorize_transform, validate=False)),\n",
    "    ('log_transformer', FunctionTransformer(log_transform, validate=False)),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# 4. Para variables numéricas sin outliers\n",
    "non_outlier_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento combinado\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('outlier_num', outlier_pipeline, outlier_features),\n",
    "        ('non_outlier_num', non_outlier_pipeline, non_outlier_features),\n",
    "        ('ord', ordinal_pipeline, ordinal_features),\n",
    "        ('nom', nominal_pipeline, low_freq_features + list(set(nominal_features) - set(low_freq_features)))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefinir pipeline completa\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Dividir los Datos en Entrenamiento y Prueba:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir los datos permite evaluar el rendimiento del modelo en datos no vistos, lo cual es esencial para verificar su capacidad de generalización. Se asumió el 80% entrenamiento y 20% prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar características (X) y variable objetivo (y)\n",
    "X = bank_data.drop(columns=['deposit'])  # Asumiendo que 'deposit' es la variable objetivo\n",
    "y = bank_data['deposit']\n",
    "\n",
    "# Dividir los datos con estratificación según la variable objetivo 'deposit'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la distribución de la variable objetivo en los conjuntos\n",
    "print(\"# --- Verificación de Estratificación --- #\")\n",
    "print(\"Distribución en el conjunto de entrenamiento:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribución en el conjunto de prueba:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar y_train y y_test en valores numéricos\n",
    "y_train = y_train.replace({'yes': 1, 'no': 0})\n",
    "y_test = y_test.replace({'yes': 1, 'no': 0})\n",
    "\n",
    "# Confirmar la codificación\n",
    "print(\"# --- Confirmación de Codificación de y_train y y_test --- #\")\n",
    "print(\"Primeras filas de y_train:\")\n",
    "print(y_train.head())\n",
    "\n",
    "print(\"\\nPrimeras filas de y_test:\")\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones**\n",
    "\n",
    "Las variables y_train y y_test han sido codificadas:\n",
    "* yes → 1 (Cliente aceptó el depósito).\n",
    "* no → 0 (Cliente no aceptó el depósito)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.  Ajustar la pipeline de preprocesamiento a los datos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La pipeline creada puede procesar automáticamente las transformaciones en las características. Primero, se ajusta la pipeline con los datos de entrenamiento y luego se aplicas tanto al conjunto de entrenamiento como al de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar y transformar\n",
    "try:\n",
    "    X_train_transformed = full_pipeline.fit_transform(X_train)\n",
    "    X_test_transformed = full_pipeline.transform(X_test)\n",
    "    print(\"Pipeline ajustado y datos transformados correctamente.\")\n",
    "except Exception as e:\n",
    "    print(\"Error durante la transformación:\", e)\n",
    "\n",
    "# Verificar las dimensiones de los datos transformados\n",
    "print(\"Dimensiones de los datos transformados:\")\n",
    "print(\"X_train_transformed:\", X_train_transformed.shape)\n",
    "print(\"X_test_transformed:\", X_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar columnas con NaN en X_train antes de la transformación\n",
    "print(\"Columnas con NaN antes de la transformación:\")\n",
    "print(X_train.isnull().sum()[X_train.isnull().sum() > 0])\n",
    "\n",
    "# Verificar columnas con NaN en X_train_transformed después de aplicar el pipeline\n",
    "transformed_df = pd.DataFrame(X_train_transformed)\n",
    "print(\"Columnas con NaN después de la transformación:\")\n",
    "print(transformed_df.isnull().sum()[transformed_df.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pd.DataFrame(X_train_transformed)\n",
    "X_train_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = pd.DataFrame(X_test_transformed)\n",
    "X_test_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Entrenar Modelo: Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Crosvalidation y entreno de modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurar el modelo y realizar validación cruzada\n",
    "\n",
    "# Crear el modelo de Regresión Logística\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Configurar K-Fold Cross Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Validación cruzada para Accuracy\n",
    "cv_accuracy_scores = cross_val_score(model, X_train_transformed, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Validación cruzada para F1-Score\n",
    "cv_f1_scores = cross_val_score(model, X_train_transformed, y_train, cv=kf, scoring='f1')\n",
    "\n",
    "# Validación cruzada para ROC-AUC\n",
    "cv_roc_auc_scores = cross_val_score(model, X_train_transformed, y_train, cv=kf, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los resultados de la validación cruzada\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_accuracy_scores}\")\n",
    "print(f\"Promedio de Accuracy: {cv_accuracy_scores.mean():.4f}\")\n",
    "print(f\"Desviación Estándar de Accuracy: {cv_accuracy_scores.std():.4f}\\n\")\n",
    "\n",
    "print(f\"Cross-Validation F1 Scores: {cv_f1_scores}\")\n",
    "print(f\"Promedio de F1-Score: {cv_f1_scores.mean():.4f}\\n\")\n",
    "\n",
    "print(f\"Cross-Validation ROC-AUC Scores: {cv_roc_auc_scores}\")\n",
    "print(f\"Promedio de ROC-AUC: {cv_roc_auc_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenar el modelo en el conjunto completo de entrenamiento\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "y_pred_proba = model.predict_proba(X_test_transformed)[:, 1]  # Obtener probabilidades para ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular las métricas de evaluación en el conjunto de prueba\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Imprimir métricas clave\n",
    "print(f\"Exactitud (Accuracy): {accuracy:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\\n\")\n",
    "\n",
    "# Mostrar el reporte de clasificación\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la matriz de confusión\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})', color='blue')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Model')\n",
    "plt.title('Curva ROC')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar métricas de validación cruzada y prueba final\n",
    "print(\"# --- Comparación de Resultados --- #\")\n",
    "print(f\"Promedio de Accuracy (Cross-Validation): {cv_accuracy_scores.mean():.4f}\")\n",
    "print(f\"Accuracy en Conjunto de Prueba: {accuracy:.4f}\\n\")\n",
    "\n",
    "print(f\"Promedio de F1-Score (Cross-Validation): {cv_f1_scores.mean():.4f}\")\n",
    "print(f\"F1-Score en Conjunto de Prueba: {f1:.4f}\\n\")\n",
    "\n",
    "print(f\"Promedio de ROC-AUC (Cross-Validation): {cv_roc_auc_scores.mean():.4f}\")\n",
    "print(f\"ROC-AUC en Conjunto de Prueba: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resumen del análisis**\n",
    "El proyecto busca crear un modelo de perfilado inteligente de clientes para maximizar la tasa de suscripción de depósitos a plazo fijo. Se evaluaron los resultados del modelo de Regresión Logística, considerando métricas clave como Accuracy, F1-Score y ROC-AUC, junto con una matriz de confusión y una curva ROC.\n",
    "\n",
    "* **Resultados principales**\n",
    "    - Accuracy (validación cruzada): 80.70% (Desviación estándar: 0.0107)\n",
    "    - F1-Score (validación cruzada): 79.76%\n",
    "    - ROC-AUC (validación cruzada): 88.43%\n",
    "\n",
    "* **Conjunto de prueba:** \n",
    "    - Accuracy: 79.80%\n",
    "    - F1-Score: 78.92%\n",
    "    - ROC-AUC: 88.23%\n",
    "\n",
    "* **Matriz de Confusión:**\n",
    "    - Falsos positivos: 237 (impacto en costos de marketing).\n",
    "    - Falsos negativos: 214 (oportunidades de negocio perdidas).\n",
    "\n",
    "* **Relación con el negocio** \n",
    "    - El modelo cumple con el objetivo principal de distinguir clientes interesados en suscribir un depósito de aquellos que no lo están, con un buen desempeño en las métricas clave.\n",
    "    - La métrica de ROC-AUC (0.88) muestra que el modelo tiene una buena capacidad para discriminar entre ambas clases, alineándose con los objetivos del negocio descritos en el documento​(Sprint_7.2_Proyecto ML).\n",
    "\n",
    "* **Fortalezas:**\n",
    "    - Un balance razonable entre precisión (accuracy) y capacidad predictiva (ROC-AUC).\n",
    "    - La F1-Score (0.7892 en el conjunto de prueba) indica que el modelo logra minimizar los falsos negativos, lo cual es crucial para evitar la pérdida de clientes potenciales.\n",
    "\n",
    "* **Debilidades:**\n",
    "    - Los falsos positivos (237) y falsos negativos (214) representan áreas donde se podría mejorar, ya que estos errores implican costos innecesarios en marketing y oportunidades perdidas, respectivamente.\n",
    "    - La desviación estándar de accuracy (0.0107) muestra una ligera variabilidad en el rendimiento del modelo durante la validación cruzada.\n",
    "\n",
    "* **Próximos pasos**\n",
    "El modelo actual de Regresión Logística es funcional y ofrece resultados sólidos, especialmente en términos de ROC-AUC (0.88). Sin embargo, se recomienda implementar técnicas de optimización para reducir los falsos negativos y positivos, mejorando la personalización de campañas y maximizando la tasa de suscripción de depósitos a plazo fijo. Esto ayudará a cumplir con los objetivos estratégicos del banco, mejorando tanto la eficacia del marketing como las tasas de conversión. \n",
    "\n",
    "    - **Optimización del modelo:** Ajustar hiperparámetros de la regresión logística para reducir los falsos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Optimización de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de Regresión Logística, los principales hiperparámetros a ajustar son:\n",
    "* C (Regularización): Controla la fuerza de la regularización. Valores más bajos implican mayor regularización.\n",
    "* penalty (Penalización): Define el tipo de regularización a aplicar. Las opciones comunes son:\n",
    "    - 'l1' para regularización Lasso.\n",
    "    - 'l2' para regularización Ridge.\n",
    "* solver (Algoritmo de optimización): Controla cómo se ajusta el modelo. Depende de la penalización elegida:\n",
    "    - 'liblinear': Compatible con 'l1' y 'l2'.\n",
    "    - 'saga': Compatible con 'l1', 'l2' y elastic net (si se requiere).\n",
    "    - 'lbfgs': Usado generalmente para 'l2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Definir los parámetros para buscar\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularización\n",
    "    'penalty': ['l1', 'l2'],       # Penalización\n",
    "    'solver': ['liblinear', 'saga'],  # Solvers compatibles\n",
    "}\n",
    "\n",
    "# Configurar la búsqueda de hiperparámetros\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=42, max_iter=1000),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # Validación cruzada con 5 particiones\n",
    "    scoring='f1',  # Métrica objetivo\n",
    "    verbose=1,  # Muestra el progreso\n",
    "    n_jobs=-1  # Usa todos los núcleos disponibles\n",
    ")\n",
    "\n",
    "# Entrenar la búsqueda de hiperparámetros\n",
    "grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Resultados\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "print(\"Mejor F1-Score durante la validación cruzada:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo final con los mejores parámetros\n",
    "best_model = LogisticRegression(**best_params, random_state=42, max_iter=1000)\n",
    "best_model.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test_transformed)\n",
    "y_pred_proba = best_model.predict_proba(X_test_transformed)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de evaluación\n",
    "accuracy = best_model.score(X_test_transformed, y_test)\n",
    "f1 = classification_report(y_test, y_pred, target_names=['No', 'Yes'])\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exactitud (Accuracy):\", accuracy)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"ROC-AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusión:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Random Model')\n",
    "plt.title('Curva ROC')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados Posteriores a la Optimización**\n",
    "\n",
    "**Métricas en el conjunto de prueba:**\n",
    "* Exactitud (Accuracy): 0.8012 (ligera mejora respecto a 0.7980 antes de la optimización).\n",
    "* F1-Score:\n",
    "* Clase No: 0.81\n",
    "* Clase Yes: 0.79 (sin cambios significativos respecto al modelo sin optimización, que tenía 0.7892).\n",
    "* ROC-AUC: 0.8823 (prácticamente idéntico al valor previo de 0.8823).\n",
    "* Matriz de Confusión:\n",
    "    - Verdaderos Positivos (TP): 847 (mejor que los 844 previos).\n",
    "    - Verdaderos Negativos (TN): 942 (ligera mejora respecto a 938).\n",
    "    - Falsos Positivos (FP): 233 (reducido respecto a 237).\n",
    "    - Falsos Negativos (FN): 211 (ligera mejora respecto a 214)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparación con el Modelo Sin Optimización**\n",
    "\n",
    "**Promedio de Métricas:**\n",
    "* Accuracy: Mejoró marginalmente de 0.7980 a 0.8012.\n",
    "* F1-Score: Sin cambios significativos (se mantiene alrededor de 0.79).\n",
    "* ROC-AUC: Sin mejora (sigue en 0.8823).\n",
    "\n",
    "* Errores:\n",
    "- FN (Falsos Negativos): Se redujeron ligeramente de 214 a 211, pero sigue siendo un área a trabajar porque representan oportunidades perdidas.\n",
    "- FP (Falsos Positivos): También se redujeron de 237 a 233, indicando una mejor asignación de recursos.\n",
    "\n",
    "* Cambios Globales:\n",
    "Los cambios son marginales, lo que indica que el modelo base estaba ya bien ajustado para los datos proporcionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión Final**\n",
    "\n",
    "**Resultados de la Optimización:**\n",
    "Aunque la optimización con GridSearchCV permitió encontrar mejores hiperparámetros, los resultados no mejoraron significativamente en comparación con el modelo base.\n",
    "Esto puede deberse a que la Regresión Logística ya alcanzó su límite de desempeño dado el conjunto de datos y las características disponibles.\n",
    "\n",
    "**Recomendación:**\n",
    "* Explora modelos más avanzados, como:Random Forests: Para capturar relaciones no lineales entre las características y/o Gradient Boosting (XGBoost o LightGBM): Para manejar mejor las clases desbalanceadas.\n",
    "* Ingeniería de características: Analizar si las variables actuales capturan toda la información relevante. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Guardar modelo y pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Guardar el modelo optimizado\n",
    "model_path = \"best_logistic_model.pkl\"\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Guardar la pipeline de transformación\n",
    "pipeline_path = \"data_transformation_pipeline.pkl\"\n",
    "with open(pipeline_path, \"wb\") as f:\n",
    "    pickle.dump(full_pipeline, f)\n",
    "\n",
    "print(f\"Modelo guardado en: {model_path}\")\n",
    "print(f\"Pipeline guardada en: {pipeline_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
