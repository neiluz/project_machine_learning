{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightgray; color:black; padding:10px; border-radius:5px;\">\n",
    "  <h1>Sprint 8</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 8: Entrena los modelos de tu proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ **Objetivo:**\n",
    "Entrenar los modelos al dataset analizado en el sprint 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 1**. Entrenar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducci√≥n\n",
    "\n",
    "En estudios previos, se realiz√≥ un an√°lisis exploratorio de datos (EDA) que permiti√≥ obtener una comprensi√≥n detallada de las caracter√≠sticas del conjunto de datos. Este an√°lisis identific√≥ variables categ√≥ricas y num√©ricas, revel√≥ patrones clave y estableci√≥ las necesidades de preprocesamiento esenciales para optimizar su uso en modelos predictivos. A continuaci√≥n, se resumen los principales hallazgos:\n",
    "\n",
    "**Clasificaci√≥n de las Variables:**\n",
    "* Num√©ricas: Identificaci√≥n de variables con asimetr√≠as, curtosis y outliers (balance, duration, campaign, pdays, previous).\n",
    "* Categ√≥ricas: Clasificaci√≥n en nominales y ordinales (education, month, job, entre otras).\n",
    "\n",
    "**Tratamiento de Variables Num√©ricas:**\n",
    "* Outliers: Winsorizaci√≥n aplicada para mitigar el impacto de valores extremos.\n",
    "* Transformaci√≥n logar√≠tmica: Usada en variables con distribuciones altamente sesgadas.\n",
    "* Escalado: RobustScaler para variables con outliers y MinMaxScaler para las dem√°s.\n",
    "\n",
    "**Imputaci√≥n de Valores Faltantes:**\n",
    "* Num√©ricas: Imputaci√≥n con la mediana.\n",
    "* Categ√≥ricas: Imputaci√≥n con \"unknown\" para mantener coherencia.\n",
    "\n",
    "**Codificaci√≥n de Variables Categ√≥ricas:**\n",
    "* Ordinales: Codificaci√≥n con valores espec√≠ficos para reflejar orden l√≥gico (education, month).\n",
    "* Nominales: One-Hot Encoding aplicado con eliminaci√≥n de la columna de referencia para reducir dimensionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo de este Estudio\n",
    "En este proyecto, se busca implementar un modelo de clasificaci√≥n, espec√≠ficamente una **Regresi√≥n Log√≠stica**, que permita predecir la probabilidad de que un cliente suscriba un dep√≥sito bancario. Para ello, se emplear√° una pipeline que automatice el preprocesamiento de los datos, asegurando la reproducibilidad de las transformaciones realizadas en los estudios previos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enfoque Metodol√≥gico\n",
    "\n",
    "* Pipeline de Transformaciones: Construir una pipeline que integre las imputaciones, transformaciones logar√≠tmicas, winsorizaci√≥n, escalado y codificaci√≥n de variables. Esto garantizar√° un flujo estructurado y replicable del preprocesamiento.\n",
    "\n",
    "* Entrenamiento del Modelo:\n",
    "    - Dividir los datos en conjuntos de entrenamiento y prueba mediante estratificaci√≥n para mantener la distribuci√≥n de la variable objetivo.\n",
    "    - Entrenar el modelo de Regresi√≥n Log√≠stica utilizando los datos preprocesados.\n",
    "\n",
    "* Evaluaci√≥n y M√©tricas:\n",
    "    - Evaluar el modelo mediante m√©tricas clave como accuracy, f1-score, roc-auc, precisi√≥n y recall.\n",
    "    - Generar una matriz de confusi√≥n para analizar los errores en la clasificaci√≥n de las clases.\n",
    "\n",
    "* Optimizaci√≥n: Ajustar los hiperpar√°metros del modelo para mejorar su desempe√±o.\n",
    "\n",
    "* Interpretaci√≥n y Comparaci√≥n: Analizar los coeficientes del modelo para identificar las variables m√°s influyentes y comparar los resultados obtenidos con los objetivos del negocio.\n",
    "\n",
    "* Guardado para Productivizaci√≥n: Al finalizar, guardar la pipeline y el modelo entrenado para su uso en producci√≥n mediante herramientas como Streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, RobustScaler, MinMaxScaler, FunctionTransformer\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, f1_score, accuracy_score,  make_scorer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Carga el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data= pd.read_csv('/home/ngonzalez/mi_pagina_personal/bank_dataset.CSV')\n",
    "bank_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Informaci√≥ general del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n inicial del DataFrame\n",
    "bank_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El m√©todo data.info() nos proporciona un resumen general del conjunto de datos:\n",
    "\n",
    "- Total de entradas: 11,162 registros con 17 columnas.\n",
    "Tipos de datos:\n",
    "- Variables num√©ricas (de tipo float64 y int64): como age, balance, day, duration, campaign, pdays, previous.\n",
    "- Variables categ√≥ricas (object): job, marital, education, default, housing, loan, contact, month, poutcome, y deposit.\n",
    "- Valores faltantes:age, marital, y education tienen algunos valores faltantes, ya manejados previamente en el an√°lisis.\n",
    "\n",
    "Este resumen nos confirma que las variables est√°n bien definidas para el an√°lisis exploratorio y el modelado posterior, permitiendo un an√°lisis demogr√°fico, financiero y de interacci√≥n de los clientes en relaci√≥n con la suscripci√≥n de dep√≥sitos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Crear Pipeline de Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificaci√≥n de variables\n",
    "ordinal_features = ['education', 'month']\n",
    "ordinal_orders = {\n",
    "    'education': ['unknown', 'primary', 'secondary', 'tertiary'],\n",
    "    'month': ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "}\n",
    "\n",
    "nominal_features = ['job', 'marital', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "low_freq_features = ['job', 'contact', 'poutcome']\n",
    "\n",
    "# Variables num√©ricas\n",
    "outlier_features = ['balance', 'duration', 'pdays']\n",
    "non_outlier_features = ['age', 'campaign', 'previous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n de Winsorizaci√≥n\n",
    "# Funci√≥n para aplicar winsorizaci√≥n\n",
    "def winsorize_transform(X):\n",
    "    return np.apply_along_axis(lambda col: winsorize(col, limits=[0.05, 0.05]), axis=0, arr=X)\n",
    "\n",
    "# Funci√≥n para transformaci√≥n logar√≠tmica\n",
    "def log_transform(X):\n",
    "    X = np.where(X <= 0, X + np.abs(X.min(axis=0)) + 1, X)  # Ajustar valores negativos o cero\n",
    "    return np.log1p(X)\n",
    "\n",
    "class LowFrequencyGrouper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.05):\n",
    "        self.threshold = threshold\n",
    "        self.low_freq_categories_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calcular categor√≠as de baja frecuencia para cada columna\n",
    "        self.low_freq_categories_ = []\n",
    "        for col in range(X.shape[1]):\n",
    "            unique, counts = np.unique(X[:, col], return_counts=True)\n",
    "            freq = counts / len(X)\n",
    "            low_freq_categories = unique[freq < self.threshold]\n",
    "            self.low_freq_categories_.append(low_freq_categories)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Reemplazar categor√≠as de baja frecuencia por 'Otros'\n",
    "        X_transformed = X.copy()\n",
    "        for col in range(X.shape[1]):\n",
    "            low_freq_categories = self.low_freq_categories_[col]\n",
    "            X_transformed[:, col] = np.where(\n",
    "                np.isin(X_transformed[:, col], low_freq_categories), 'Otros', X_transformed[:, col]\n",
    "            )\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines individuales\n",
    "# 1. Para variables ordinales\n",
    "ordinal_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('ordinal_encoder', OrdinalEncoder(categories=[ordinal_orders[feature] for feature in ordinal_features]))\n",
    "])\n",
    "\n",
    "# 2. Para variables nominales con agrupamiento de baja frecuencia\n",
    "nominal_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('low_freq_grouper', LowFrequencyGrouper(threshold=0.05)),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False))\n",
    "])\n",
    "\n",
    "# 3. Para variables num√©ricas con outliers\n",
    "outlier_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('winsorizer', FunctionTransformer(winsorize_transform, validate=False)),\n",
    "    ('log_transformer', FunctionTransformer(log_transform, validate=False)),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# 4. Para variables num√©ricas sin outliers\n",
    "non_outlier_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento combinado\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('outlier_num', outlier_pipeline, outlier_features),\n",
    "        ('non_outlier_num', non_outlier_pipeline, non_outlier_features),\n",
    "        ('ord', ordinal_pipeline, ordinal_features),\n",
    "        ('nom', nominal_pipeline, low_freq_features + list(set(nominal_features) - set(low_freq_features)))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefinir pipeline completa\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Dividir los Datos en Entrenamiento y Prueba:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir los datos permite evaluar el rendimiento del modelo en datos no vistos, lo cual es esencial para verificar su capacidad de generalizaci√≥n. Se asumi√≥ el 80% entrenamiento y 20% prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar caracter√≠sticas (X) y variable objetivo (y)\n",
    "X = bank_data.drop(columns=['deposit'])  # Asumiendo que 'deposit' es la variable objetivo\n",
    "y = bank_data['deposit']\n",
    "\n",
    "# Dividir los datos con estratificaci√≥n seg√∫n la variable objetivo 'deposit'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la distribuci√≥n de la variable objetivo en los conjuntos\n",
    "print(\"# --- Verificaci√≥n de Estratificaci√≥n --- #\")\n",
    "print(\"Distribuci√≥n en el conjunto de entrenamiento:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribuci√≥n en el conjunto de prueba:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar y_train y y_test en valores num√©ricos\n",
    "y_train = y_train.replace({'yes': 1, 'no': 0})\n",
    "y_test = y_test.replace({'yes': 1, 'no': 0})\n",
    "\n",
    "# Confirmar la codificaci√≥n\n",
    "print(\"# --- Confirmaci√≥n de Codificaci√≥n de y_train y y_test --- #\")\n",
    "print(\"Primeras filas de y_train:\")\n",
    "print(y_train.head())\n",
    "\n",
    "print(\"\\nPrimeras filas de y_test:\")\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones**\n",
    "\n",
    "Las variables y_train y y_test han sido codificadas:\n",
    "* yes ‚Üí 1 (Cliente acept√≥ el dep√≥sito).\n",
    "* no ‚Üí 0 (Cliente no acept√≥ el dep√≥sito)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.  Ajustar la pipeline de preprocesamiento a los datos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La pipeline creada puede procesar autom√°ticamente las transformaciones en las caracter√≠sticas. Primero, se ajusta la pipeline con los datos de entrenamiento y luego se aplicas tanto al conjunto de entrenamiento como al de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar y transformar\n",
    "try:\n",
    "    X_train_transformed = full_pipeline.fit_transform(X_train)\n",
    "    X_test_transformed = full_pipeline.transform(X_test)\n",
    "    print(\"Pipeline ajustado y datos transformados correctamente.\")\n",
    "except Exception as e:\n",
    "    print(\"Error durante la transformaci√≥n:\", e)\n",
    "\n",
    "# Verificar las dimensiones de los datos transformados\n",
    "print(\"Dimensiones de los datos transformados:\")\n",
    "print(\"X_train_transformed:\", X_train_transformed.shape)\n",
    "print(\"X_test_transformed:\", X_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar columnas con NaN en X_train antes de la transformaci√≥n\n",
    "print(\"Columnas con NaN antes de la transformaci√≥n:\")\n",
    "print(X_train.isnull().sum()[X_train.isnull().sum() > 0])\n",
    "\n",
    "# Verificar columnas con NaN en X_train_transformed despu√©s de aplicar el pipeline\n",
    "transformed_df = pd.DataFrame(X_train_transformed)\n",
    "print(\"Columnas con NaN despu√©s de la transformaci√≥n:\")\n",
    "print(transformed_df.isnull().sum()[transformed_df.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pd.DataFrame(X_train_transformed)\n",
    "X_train_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = pd.DataFrame(X_test_transformed)\n",
    "X_test_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Entrenar Modelo: Regresi√≥n Log√≠stica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Crosvalidation y entreno de modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurar el modelo y realizar validaci√≥n cruzada\n",
    "\n",
    "# Crear el modelo de Regresi√≥n Log√≠stica\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Configurar K-Fold Cross Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Validaci√≥n cruzada para Accuracy\n",
    "cv_accuracy_scores = cross_val_score(model, X_train_transformed, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Validaci√≥n cruzada para F1-Score\n",
    "cv_f1_scores = cross_val_score(model, X_train_transformed, y_train, cv=kf, scoring='f1')\n",
    "\n",
    "# Validaci√≥n cruzada para ROC-AUC\n",
    "cv_roc_auc_scores = cross_val_score(model, X_train_transformed, y_train, cv=kf, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los resultados de la validaci√≥n cruzada\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_accuracy_scores}\")\n",
    "print(f\"Promedio de Accuracy: {cv_accuracy_scores.mean():.4f}\")\n",
    "print(f\"Desviaci√≥n Est√°ndar de Accuracy: {cv_accuracy_scores.std():.4f}\\n\")\n",
    "\n",
    "print(f\"Cross-Validation F1 Scores: {cv_f1_scores}\")\n",
    "print(f\"Promedio de F1-Score: {cv_f1_scores.mean():.4f}\\n\")\n",
    "\n",
    "print(f\"Cross-Validation ROC-AUC Scores: {cv_roc_auc_scores}\")\n",
    "print(f\"Promedio de ROC-AUC: {cv_roc_auc_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenar el modelo en el conjunto completo de entrenamiento\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "y_pred_proba = model.predict_proba(X_test_transformed)[:, 1]  # Obtener probabilidades para ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular las m√©tricas de evaluaci√≥n en el conjunto de prueba\n",
    "# Calcular m√©tricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Imprimir m√©tricas clave\n",
    "print(f\"Exactitud (Accuracy): {accuracy:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\\n\")\n",
    "\n",
    "# Mostrar el reporte de clasificaci√≥n\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Mostrar la matriz de confusi√≥n\n",
    "print(\"Matriz de Confusi√≥n:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la matriz de confusi√≥n\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.title('Matriz de Confusi√≥n')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})', color='blue')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Model')\n",
    "plt.title('Curva ROC')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar m√©tricas de validaci√≥n cruzada y prueba final\n",
    "print(\"# --- Comparaci√≥n de Resultados --- #\")\n",
    "print(f\"Promedio de Accuracy (Cross-Validation): {cv_accuracy_scores.mean():.4f}\")\n",
    "print(f\"Accuracy en Conjunto de Prueba: {accuracy:.4f}\\n\")\n",
    "\n",
    "print(f\"Promedio de F1-Score (Cross-Validation): {cv_f1_scores.mean():.4f}\")\n",
    "print(f\"F1-Score en Conjunto de Prueba: {f1:.4f}\\n\")\n",
    "\n",
    "print(f\"Promedio de ROC-AUC (Cross-Validation): {cv_roc_auc_scores.mean():.4f}\")\n",
    "print(f\"ROC-AUC en Conjunto de Prueba: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resumen del an√°lisis**\n",
    "El proyecto busca crear un modelo de perfilado inteligente de clientes para maximizar la tasa de suscripci√≥n de dep√≥sitos a plazo fijo. Se evaluaron los resultados del modelo de Regresi√≥n Log√≠stica, considerando m√©tricas clave como Accuracy, F1-Score y ROC-AUC, junto con una matriz de confusi√≥n y una curva ROC.\n",
    "\n",
    "* **Resultados principales**\n",
    "    - Accuracy (validaci√≥n cruzada): 80.70% (Desviaci√≥n est√°ndar: 0.0107)\n",
    "    - F1-Score (validaci√≥n cruzada): 79.76%\n",
    "    - ROC-AUC (validaci√≥n cruzada): 88.43%\n",
    "\n",
    "* **Conjunto de prueba:** \n",
    "    - Accuracy: 79.80%\n",
    "    - F1-Score: 78.92%\n",
    "    - ROC-AUC: 88.23%\n",
    "\n",
    "* **Matriz de Confusi√≥n:**\n",
    "    - Falsos positivos: 237 (impacto en costos de marketing).\n",
    "    - Falsos negativos: 214 (oportunidades de negocio perdidas).\n",
    "\n",
    "* **Relaci√≥n con el negocio** \n",
    "    - El modelo cumple con el objetivo principal de distinguir clientes interesados en suscribir un dep√≥sito de aquellos que no lo est√°n, con un buen desempe√±o en las m√©tricas clave.\n",
    "    - La m√©trica de ROC-AUC (0.88) muestra que el modelo tiene una buena capacidad para discriminar entre ambas clases, aline√°ndose con los objetivos del negocio descritos en el documento‚Äã(Sprint_7.2_Proyecto ML).\n",
    "\n",
    "* **Fortalezas:**\n",
    "    - Un balance razonable entre precisi√≥n (accuracy) y capacidad predictiva (ROC-AUC).\n",
    "    - La F1-Score (0.7892 en el conjunto de prueba) indica que el modelo logra minimizar los falsos negativos, lo cual es crucial para evitar la p√©rdida de clientes potenciales.\n",
    "\n",
    "* **Debilidades:**\n",
    "    - Los falsos positivos (237) y falsos negativos (214) representan √°reas donde se podr√≠a mejorar, ya que estos errores implican costos innecesarios en marketing y oportunidades perdidas, respectivamente.\n",
    "    - La desviaci√≥n est√°ndar de accuracy (0.0107) muestra una ligera variabilidad en el rendimiento del modelo durante la validaci√≥n cruzada.\n",
    "\n",
    "* **Pr√≥ximos pasos**\n",
    "El modelo actual de Regresi√≥n Log√≠stica es funcional y ofrece resultados s√≥lidos, especialmente en t√©rminos de ROC-AUC (0.88). Sin embargo, se recomienda implementar t√©cnicas de optimizaci√≥n para reducir los falsos negativos y positivos, mejorando la personalizaci√≥n de campa√±as y maximizando la tasa de suscripci√≥n de dep√≥sitos a plazo fijo. Esto ayudar√° a cumplir con los objetivos estrat√©gicos del banco, mejorando tanto la eficacia del marketing como las tasas de conversi√≥n. \n",
    "\n",
    "    - **Optimizaci√≥n del modelo:** Ajustar hiperpar√°metros de la regresi√≥n log√≠stica para reducir los falsos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Optimizaci√≥n de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de Regresi√≥n Log√≠stica, los principales hiperpar√°metros a ajustar son:\n",
    "* C (Regularizaci√≥n): Controla la fuerza de la regularizaci√≥n. Valores m√°s bajos implican mayor regularizaci√≥n.\n",
    "* penalty (Penalizaci√≥n): Define el tipo de regularizaci√≥n a aplicar. Las opciones comunes son:\n",
    "    - 'l1' para regularizaci√≥n Lasso.\n",
    "    - 'l2' para regularizaci√≥n Ridge.\n",
    "* solver (Algoritmo de optimizaci√≥n): Controla c√≥mo se ajusta el modelo. Depende de la penalizaci√≥n elegida:\n",
    "    - 'liblinear': Compatible con 'l1' y 'l2'.\n",
    "    - 'saga': Compatible con 'l1', 'l2' y elastic net (si se requiere).\n",
    "    - 'lbfgs': Usado generalmente para 'l2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Definir los par√°metros para buscar\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularizaci√≥n\n",
    "    'penalty': ['l1', 'l2'],       # Penalizaci√≥n\n",
    "    'solver': ['liblinear', 'saga'],  # Solvers compatibles\n",
    "}\n",
    "\n",
    "# Configurar la b√∫squeda de hiperpar√°metros\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=42, max_iter=1000),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # Validaci√≥n cruzada con 5 particiones\n",
    "    scoring='f1',  # M√©trica objetivo\n",
    "    verbose=1,  # Muestra el progreso\n",
    "    n_jobs=-1  # Usa todos los n√∫cleos disponibles\n",
    ")\n",
    "\n",
    "# Entrenar la b√∫squeda de hiperpar√°metros\n",
    "grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Resultados\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Mejores par√°metros:\", best_params)\n",
    "print(\"Mejor F1-Score durante la validaci√≥n cruzada:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo final con los mejores par√°metros\n",
    "best_model = LogisticRegression(**best_params, random_state=42, max_iter=1000)\n",
    "best_model.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test_transformed)\n",
    "y_pred_proba = best_model.predict_proba(X_test_transformed)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√©tricas de evaluaci√≥n\n",
    "accuracy = best_model.score(X_test_transformed, y_test)\n",
    "f1 = classification_report(y_test, y_pred, target_names=['No', 'Yes'])\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exactitud (Accuracy):\", accuracy)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"ROC-AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusi√≥n\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusi√≥n:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Random Model')\n",
    "plt.title('Curva ROC')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados Posteriores a la Optimizaci√≥n**\n",
    "\n",
    "**M√©tricas en el conjunto de prueba:**\n",
    "* Exactitud (Accuracy): 0.8012 (ligera mejora respecto a 0.7980 antes de la optimizaci√≥n).\n",
    "* F1-Score:\n",
    "* Clase No: 0.81\n",
    "* Clase Yes: 0.79 (sin cambios significativos respecto al modelo sin optimizaci√≥n, que ten√≠a 0.7892).\n",
    "* ROC-AUC: 0.8823 (pr√°cticamente id√©ntico al valor previo de 0.8823).\n",
    "* Matriz de Confusi√≥n:\n",
    "    - Verdaderos Positivos (TP): 847 (mejor que los 844 previos).\n",
    "    - Verdaderos Negativos (TN): 942 (ligera mejora respecto a 938).\n",
    "    - Falsos Positivos (FP): 233 (reducido respecto a 237).\n",
    "    - Falsos Negativos (FN): 211 (ligera mejora respecto a 214)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparaci√≥n con el Modelo Sin Optimizaci√≥n**\n",
    "\n",
    "**Promedio de M√©tricas:**\n",
    "* Accuracy: Mejor√≥ marginalmente de 0.7980 a 0.8012.\n",
    "* F1-Score: Sin cambios significativos (se mantiene alrededor de 0.79).\n",
    "* ROC-AUC: Sin mejora (sigue en 0.8823).\n",
    "\n",
    "* Errores:\n",
    "- FN (Falsos Negativos): Se redujeron ligeramente de 214 a 211, pero sigue siendo un √°rea a trabajar porque representan oportunidades perdidas.\n",
    "- FP (Falsos Positivos): Tambi√©n se redujeron de 237 a 233, indicando una mejor asignaci√≥n de recursos.\n",
    "\n",
    "* Cambios Globales:\n",
    "Los cambios son marginales, lo que indica que el modelo base estaba ya bien ajustado para los datos proporcionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusi√≥n Final**\n",
    "\n",
    "**Resultados de la Optimizaci√≥n:**\n",
    "Aunque la optimizaci√≥n con GridSearchCV permiti√≥ encontrar mejores hiperpar√°metros, los resultados no mejoraron significativamente en comparaci√≥n con el modelo base.\n",
    "Esto puede deberse a que la Regresi√≥n Log√≠stica ya alcanz√≥ su l√≠mite de desempe√±o dado el conjunto de datos y las caracter√≠sticas disponibles.\n",
    "\n",
    "**Recomendaci√≥n:**\n",
    "* Explora modelos m√°s avanzados, como:Random Forests: Para capturar relaciones no lineales entre las caracter√≠sticas y/o Gradient Boosting (XGBoost o LightGBM): Para manejar mejor las clases desbalanceadas.\n",
    "* Ingenier√≠a de caracter√≠sticas: Analizar si las variables actuales capturan toda la informaci√≥n relevante. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Guardar modelo y pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Guardar el modelo optimizado\n",
    "model_path = \"best_logistic_model.pkl\"\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Guardar la pipeline de transformaci√≥n\n",
    "pipeline_path = \"data_transformation_pipeline.pkl\"\n",
    "with open(pipeline_path, \"wb\") as f:\n",
    "    pickle.dump(full_pipeline, f)\n",
    "\n",
    "print(f\"Modelo guardado en: {model_path}\")\n",
    "print(f\"Pipeline guardada en: {pipeline_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
